{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9073122,"sourceType":"datasetVersion","datasetId":5472989}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Breakhis-400x Dataset","metadata":{}},{"cell_type":"markdown","source":"# Block 1","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breakhis-400x/Breakhis-400x'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 2\nepochs = 100\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator_balanced, epochs=epochs, validation_data=validation_generator_balanced, class_weight=class_weights_balanced)\n\n# Evaluate the model on the test set\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\nloss, accuracy = model.evaluate(test_generator)\nprint('Loss:',loss)\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:37:27.250656Z","iopub.execute_input":"2024-11-12T06:37:27.251517Z","iopub.status.idle":"2024-11-12T06:48:20.948391Z","shell.execute_reply.started":"2024-11-12T06:37:27.251484Z","shell.execute_reply":"2024-11-12T06:48:20.947451Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 1275 images belonging to 2 classes.\nFound 545 images belonging to 2 classes.\nEpoch 1/100\n\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5312 - loss: 81.3201","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731393450.275757     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5259 - loss: 47.1409","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731393455.245181     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5281 - loss: 43.3693","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731393456.407575     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - accuracy: 0.5287 - loss: 42.7057 - val_accuracy: 0.3248 - val_loss: 2.0324\nEpoch 2/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6495 - loss: 0.8804 - val_accuracy: 0.7651 - val_loss: 0.4687\nEpoch 3/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.7740 - loss: 0.4938 - val_accuracy: 0.8183 - val_loss: 0.4068\nEpoch 4/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.8061 - loss: 0.4234 - val_accuracy: 0.8147 - val_loss: 0.3999\nEpoch 5/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.8862 - loss: 0.3175 - val_accuracy: 0.7890 - val_loss: 0.4622\nEpoch 6/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.8313 - loss: 0.3770 - val_accuracy: 0.6165 - val_loss: 0.7042\nEpoch 7/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8928 - loss: 0.2915 - val_accuracy: 0.8422 - val_loss: 0.3705\nEpoch 8/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9288 - loss: 0.2057 - val_accuracy: 0.8550 - val_loss: 0.3474\nEpoch 9/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9652 - loss: 0.1125 - val_accuracy: 0.8404 - val_loss: 0.3655\nEpoch 10/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.9790 - loss: 0.0964 - val_accuracy: 0.8587 - val_loss: 0.3268\nEpoch 11/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.9903 - loss: 0.0562 - val_accuracy: 0.8404 - val_loss: 0.3756\nEpoch 12/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.9916 - loss: 0.0637 - val_accuracy: 0.8239 - val_loss: 0.4089\nEpoch 13/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9984 - loss: 0.0351 - val_accuracy: 0.8312 - val_loss: 0.3812\nEpoch 14/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.8422 - val_loss: 0.3871\nEpoch 15/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.8404 - val_loss: 0.4267\nEpoch 16/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8550 - val_loss: 0.3945\nEpoch 17/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8679 - val_loss: 0.3779\nEpoch 18/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8532 - val_loss: 0.4012\nEpoch 19/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.8477 - val_loss: 0.4240\nEpoch 20/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8459 - val_loss: 0.4294\nEpoch 21/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8514 - val_loss: 0.4340\nEpoch 22/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8440 - val_loss: 0.4488\nEpoch 23/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8422 - val_loss: 0.4644\nEpoch 24/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8514 - val_loss: 0.4543\nEpoch 25/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8532 - val_loss: 0.4852\nEpoch 26/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8569 - val_loss: 0.4865\nEpoch 27/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8459 - val_loss: 0.4839\nEpoch 28/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8330 - val_loss: 0.5211\nEpoch 29/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8569 - val_loss: 0.4917\nEpoch 30/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 8.3973e-04 - val_accuracy: 0.8532 - val_loss: 0.5066\nEpoch 31/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 7.7317e-04 - val_accuracy: 0.8587 - val_loss: 0.5010\nEpoch 32/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 6.4955e-04 - val_accuracy: 0.8532 - val_loss: 0.5120\nEpoch 33/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 5.8743e-04 - val_accuracy: 0.8624 - val_loss: 0.5066\nEpoch 34/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 5.8877e-04 - val_accuracy: 0.8569 - val_loss: 0.5266\nEpoch 35/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 5.1762e-04 - val_accuracy: 0.8587 - val_loss: 0.5192\nEpoch 36/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 4.8101e-04 - val_accuracy: 0.8587 - val_loss: 0.5222\nEpoch 37/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 4.2591e-04 - val_accuracy: 0.8495 - val_loss: 0.5599\nEpoch 38/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 4.1770e-04 - val_accuracy: 0.8514 - val_loss: 0.5500\nEpoch 39/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 3.7746e-04 - val_accuracy: 0.8587 - val_loss: 0.5407\nEpoch 40/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 3.4798e-04 - val_accuracy: 0.8587 - val_loss: 0.5433\nEpoch 41/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 3.4002e-04 - val_accuracy: 0.8459 - val_loss: 0.5866\nEpoch 42/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 3.0164e-04 - val_accuracy: 0.8532 - val_loss: 0.5656\nEpoch 43/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 2.8128e-04 - val_accuracy: 0.8587 - val_loss: 0.5574\nEpoch 44/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 2.5479e-04 - val_accuracy: 0.8514 - val_loss: 0.5659\nEpoch 45/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 2.6624e-04 - val_accuracy: 0.8514 - val_loss: 0.5714\nEpoch 46/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 2.3665e-04 - val_accuracy: 0.8514 - val_loss: 0.5801\nEpoch 47/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 2.1465e-04 - val_accuracy: 0.8550 - val_loss: 0.5747\nEpoch 48/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.1348e-04 - val_accuracy: 0.8495 - val_loss: 0.5963\nEpoch 49/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 2.0078e-04 - val_accuracy: 0.8569 - val_loss: 0.5792\nEpoch 50/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.9088e-04 - val_accuracy: 0.8532 - val_loss: 0.5802\nEpoch 51/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.8554e-04 - val_accuracy: 0.8514 - val_loss: 0.5905\nEpoch 52/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 1.7068e-04 - val_accuracy: 0.8514 - val_loss: 0.6016\nEpoch 53/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 1.6505e-04 - val_accuracy: 0.8514 - val_loss: 0.6103\nEpoch 54/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 1.5674e-04 - val_accuracy: 0.8569 - val_loss: 0.5957\nEpoch 55/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.5301e-04 - val_accuracy: 0.8514 - val_loss: 0.6157\nEpoch 56/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.4225e-04 - val_accuracy: 0.8514 - val_loss: 0.6137\nEpoch 57/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.3496e-04 - val_accuracy: 0.8495 - val_loss: 0.6269\nEpoch 58/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.3863e-04 - val_accuracy: 0.8550 - val_loss: 0.6003\nEpoch 59/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.2424e-04 - val_accuracy: 0.8514 - val_loss: 0.6215\nEpoch 60/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.1294e-04 - val_accuracy: 0.8532 - val_loss: 0.6168\nEpoch 61/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.0385e-04 - val_accuracy: 0.8532 - val_loss: 0.6230\nEpoch 62/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 1.0264e-04 - val_accuracy: 0.8514 - val_loss: 0.6314\nEpoch 63/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 9.6577e-05 - val_accuracy: 0.8514 - val_loss: 0.6401\nEpoch 64/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 9.5079e-05 - val_accuracy: 0.8550 - val_loss: 0.6208\nEpoch 65/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 9.0118e-05 - val_accuracy: 0.8550 - val_loss: 0.6246\nEpoch 66/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 9.2151e-05 - val_accuracy: 0.8532 - val_loss: 0.6312\nEpoch 67/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 8.0509e-05 - val_accuracy: 0.8532 - val_loss: 0.6475\nEpoch 68/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 8.3346e-05 - val_accuracy: 0.8532 - val_loss: 0.6377\nEpoch 69/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 8.2418e-05 - val_accuracy: 0.8514 - val_loss: 0.6529\nEpoch 70/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 7.7935e-05 - val_accuracy: 0.8514 - val_loss: 0.6490\nEpoch 71/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 7.3929e-05 - val_accuracy: 0.8477 - val_loss: 0.6655\nEpoch 72/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 6.6197e-05 - val_accuracy: 0.8569 - val_loss: 0.6395\nEpoch 73/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 7.3017e-05 - val_accuracy: 0.8550 - val_loss: 0.6399\nEpoch 74/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 6.3984e-05 - val_accuracy: 0.8532 - val_loss: 0.6481\nEpoch 75/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 6.3704e-05 - val_accuracy: 0.8532 - val_loss: 0.6590\nEpoch 76/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 6.0309e-05 - val_accuracy: 0.8550 - val_loss: 0.6547\nEpoch 77/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 5.7677e-05 - val_accuracy: 0.8550 - val_loss: 0.6505\nEpoch 78/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 5.8504e-05 - val_accuracy: 0.8514 - val_loss: 0.6739\nEpoch 79/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 5.2304e-05 - val_accuracy: 0.8532 - val_loss: 0.6643\nEpoch 80/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 5.0527e-05 - val_accuracy: 0.8532 - val_loss: 0.6682\nEpoch 81/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 4.9540e-05 - val_accuracy: 0.8550 - val_loss: 0.6714\nEpoch 82/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 4.6761e-05 - val_accuracy: 0.8514 - val_loss: 0.6735\nEpoch 83/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 4.4093e-05 - val_accuracy: 0.8459 - val_loss: 0.6955\nEpoch 84/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 4.3483e-05 - val_accuracy: 0.8550 - val_loss: 0.6741\nEpoch 85/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 4.0611e-05 - val_accuracy: 0.8514 - val_loss: 0.6876\nEpoch 86/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 4.0674e-05 - val_accuracy: 0.8569 - val_loss: 0.6699\nEpoch 87/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 4.1570e-05 - val_accuracy: 0.8569 - val_loss: 0.6764\nEpoch 88/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 3.8095e-05 - val_accuracy: 0.8514 - val_loss: 0.6910\nEpoch 89/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 4.0124e-05 - val_accuracy: 0.8569 - val_loss: 0.6879\nEpoch 90/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.8271e-05 - val_accuracy: 0.8532 - val_loss: 0.6839\nEpoch 91/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 3.5308e-05 - val_accuracy: 0.8532 - val_loss: 0.6921\nEpoch 92/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.4901e-05 - val_accuracy: 0.8550 - val_loss: 0.6868\nEpoch 93/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 3.1533e-05 - val_accuracy: 0.8550 - val_loss: 0.6878\nEpoch 94/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 3.1924e-05 - val_accuracy: 0.8532 - val_loss: 0.6988\nEpoch 95/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.1068e-05 - val_accuracy: 0.8532 - val_loss: 0.7048\nEpoch 96/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.9594e-05 - val_accuracy: 0.8514 - val_loss: 0.7112\nEpoch 97/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 2.9090e-05 - val_accuracy: 0.8550 - val_loss: 0.6994\nEpoch 98/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 3.0326e-05 - val_accuracy: 0.8569 - val_loss: 0.6975\nEpoch 99/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 2.8252e-05 - val_accuracy: 0.8550 - val_loss: 0.7077\nEpoch 100/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 2.5237e-05 - val_accuracy: 0.8550 - val_loss: 0.7010\nFound 1820 images belonging to 2 classes.\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8940 - loss: 0.5157\nLoss: 0.2099447399377823\nTest Accuracy: 95.66%\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394100.928665     178 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Block 2","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breakhis-400x/Breakhis-400x'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 2\nepochs = 100\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator_balanced, epochs=epochs, validation_data=validation_generator_balanced, class_weight=class_weights_balanced)\n\n# Evaluate the model on the test set\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\nloss, accuracy = model.evaluate(test_generator)\nprint('Loss:',loss)\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T06:48:20.950050Z","iopub.execute_input":"2024-11-12T06:48:20.950347Z","iopub.status.idle":"2024-11-12T06:59:06.885583Z","shell.execute_reply.started":"2024-11-12T06:48:20.950320Z","shell.execute_reply":"2024-11-12T06:59:06.884662Z"}},"outputs":[{"name":"stdout","text":"Found 1275 images belonging to 2 classes.\nFound 545 images belonging to 2 classes.\nEpoch 1/100\n\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4688 - loss: 18.7953","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394103.951784     178 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 701ms/step - accuracy: 0.4424 - loss: 21.5848","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394107.391067     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5744 - loss: 8.2710","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394111.274580     177 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - accuracy: 0.5767 - loss: 8.1438 - val_accuracy: 0.7284 - val_loss: 0.4431\nEpoch 2/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.7023 - loss: 0.6633 - val_accuracy: 0.8606 - val_loss: 0.4394\nEpoch 3/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7788 - loss: 0.5186 - val_accuracy: 0.7596 - val_loss: 0.5959\nEpoch 4/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7786 - loss: 0.6072 - val_accuracy: 0.7523 - val_loss: 0.5459\nEpoch 5/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8326 - loss: 0.5668 - val_accuracy: 0.7248 - val_loss: 0.5169\nEpoch 6/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.7993 - loss: 0.5298 - val_accuracy: 0.7578 - val_loss: 0.5383\nEpoch 7/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8136 - loss: 0.4470 - val_accuracy: 0.6826 - val_loss: 0.5909\nEpoch 8/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 0.8062 - loss: 0.4299 - val_accuracy: 0.8330 - val_loss: 0.3629\nEpoch 9/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.8471 - loss: 0.4186 - val_accuracy: 0.7394 - val_loss: 0.4875\nEpoch 10/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8873 - loss: 0.3249 - val_accuracy: 0.8018 - val_loss: 0.3966\nEpoch 11/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.8589 - loss: 0.3240 - val_accuracy: 0.8239 - val_loss: 0.3481\nEpoch 12/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6833 - loss: 0.5208 - val_accuracy: 0.7229 - val_loss: 0.7114\nEpoch 13/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.8941 - loss: 0.2538 - val_accuracy: 0.7486 - val_loss: 0.5619\nEpoch 14/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9179 - loss: 0.2209 - val_accuracy: 0.7688 - val_loss: 0.5234\nEpoch 15/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8570 - loss: 0.2730 - val_accuracy: 0.7083 - val_loss: 1.1721\nEpoch 16/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9420 - loss: 0.1629 - val_accuracy: 0.6991 - val_loss: 0.8380\nEpoch 17/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.9572 - loss: 0.1318 - val_accuracy: 0.6697 - val_loss: 1.0121\nEpoch 18/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9756 - loss: 0.0952 - val_accuracy: 0.7413 - val_loss: 0.8641\nEpoch 19/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.9797 - loss: 0.0687 - val_accuracy: 0.7321 - val_loss: 1.2474\nEpoch 20/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9871 - loss: 0.0409 - val_accuracy: 0.6899 - val_loss: 1.5012\nEpoch 21/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9936 - loss: 0.0308 - val_accuracy: 0.7229 - val_loss: 1.1078\nEpoch 22/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9991 - loss: 0.0136 - val_accuracy: 0.7431 - val_loss: 1.2841\nEpoch 23/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9984 - loss: 0.0095 - val_accuracy: 0.7615 - val_loss: 0.9825\nEpoch 24/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7138 - val_loss: 1.2015\nEpoch 25/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.7211 - val_loss: 1.4785\nEpoch 26/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7376 - val_loss: 1.5034\nEpoch 27/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7468 - val_loss: 1.5190\nEpoch 28/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 8.7018e-04 - val_accuracy: 0.7505 - val_loss: 1.5497\nEpoch 29/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 5.8207e-04 - val_accuracy: 0.7523 - val_loss: 1.5685\nEpoch 30/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 5.0397e-04 - val_accuracy: 0.7431 - val_loss: 1.6276\nEpoch 31/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 3.5090e-04 - val_accuracy: 0.7523 - val_loss: 1.6162\nEpoch 32/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 2.7117e-04 - val_accuracy: 0.7523 - val_loss: 1.6456\nEpoch 33/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 2.6371e-04 - val_accuracy: 0.7578 - val_loss: 1.5963\nEpoch 34/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.2837e-04 - val_accuracy: 0.7541 - val_loss: 1.6508\nEpoch 35/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 1.8083e-04 - val_accuracy: 0.7596 - val_loss: 1.5944\nEpoch 36/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 1.2168e-04 - val_accuracy: 0.7468 - val_loss: 1.6652\nEpoch 37/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.1523e-04 - val_accuracy: 0.7413 - val_loss: 1.7415\nEpoch 38/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 9.2703e-05 - val_accuracy: 0.7413 - val_loss: 1.7197\nEpoch 39/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 7.7458e-05 - val_accuracy: 0.7468 - val_loss: 1.6708\nEpoch 40/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 6.3033e-05 - val_accuracy: 0.7413 - val_loss: 1.7278\nEpoch 41/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 5.1490e-05 - val_accuracy: 0.7413 - val_loss: 1.7483\nEpoch 42/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 4.6247e-05 - val_accuracy: 0.7339 - val_loss: 1.7788\nEpoch 43/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 3.6871e-05 - val_accuracy: 0.7394 - val_loss: 1.7721\nEpoch 44/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 3.4489e-05 - val_accuracy: 0.7376 - val_loss: 1.7881\nEpoch 45/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 3.5479e-05 - val_accuracy: 0.7376 - val_loss: 1.8117\nEpoch 46/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 2.4759e-05 - val_accuracy: 0.7394 - val_loss: 1.8071\nEpoch 47/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 2.1803e-05 - val_accuracy: 0.7394 - val_loss: 1.8176\nEpoch 48/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 1.9215e-05 - val_accuracy: 0.7394 - val_loss: 1.8238\nEpoch 49/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 1.9107e-05 - val_accuracy: 0.7394 - val_loss: 1.8489\nEpoch 50/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.6295e-05 - val_accuracy: 0.7358 - val_loss: 1.8783\nEpoch 51/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.3735e-05 - val_accuracy: 0.7376 - val_loss: 1.8794\nEpoch 52/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.2898e-05 - val_accuracy: 0.7394 - val_loss: 1.8884\nEpoch 53/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.5467e-05 - val_accuracy: 0.7394 - val_loss: 1.8961\nEpoch 54/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.3297e-05 - val_accuracy: 0.7376 - val_loss: 1.9180\nEpoch 55/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.1274e-05 - val_accuracy: 0.7394 - val_loss: 1.9213\nEpoch 56/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 1.0940e-05 - val_accuracy: 0.7376 - val_loss: 1.9130\nEpoch 57/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.0832e-05 - val_accuracy: 0.7358 - val_loss: 1.9359\nEpoch 58/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 9.3585e-06 - val_accuracy: 0.7339 - val_loss: 1.9760\nEpoch 59/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 9.3735e-06 - val_accuracy: 0.7376 - val_loss: 1.9580\nEpoch 60/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 7.8586e-06 - val_accuracy: 0.7339 - val_loss: 1.9894\nEpoch 61/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 8.1366e-06 - val_accuracy: 0.7339 - val_loss: 1.9891\nEpoch 62/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 7.2807e-06 - val_accuracy: 0.7376 - val_loss: 1.9841\nEpoch 63/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 7.0083e-06 - val_accuracy: 0.7358 - val_loss: 1.9903\nEpoch 64/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 6.7961e-06 - val_accuracy: 0.7339 - val_loss: 2.0011\nEpoch 65/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 6.1657e-06 - val_accuracy: 0.7339 - val_loss: 2.0080\nEpoch 66/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 5.3174e-06 - val_accuracy: 0.7358 - val_loss: 2.0093\nEpoch 67/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 5.3362e-06 - val_accuracy: 0.7339 - val_loss: 2.0268\nEpoch 68/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 5.0471e-06 - val_accuracy: 0.7358 - val_loss: 2.0195\nEpoch 69/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 5.2487e-06 - val_accuracy: 0.7303 - val_loss: 2.0413\nEpoch 70/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 5.1394e-06 - val_accuracy: 0.7376 - val_loss: 2.0318\nEpoch 71/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 5.0668e-06 - val_accuracy: 0.7358 - val_loss: 2.0461\nEpoch 72/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 4.6767e-06 - val_accuracy: 0.7321 - val_loss: 2.0579\nEpoch 73/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.7684e-06 - val_accuracy: 0.7339 - val_loss: 2.0579\nEpoch 74/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 4.2269e-06 - val_accuracy: 0.7303 - val_loss: 2.0766\nEpoch 75/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 4.1121e-06 - val_accuracy: 0.7321 - val_loss: 2.0754\nEpoch 76/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 3.5807e-06 - val_accuracy: 0.7303 - val_loss: 2.0974\nEpoch 77/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 3.6712e-06 - val_accuracy: 0.7266 - val_loss: 2.0921\nEpoch 78/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 3.5731e-06 - val_accuracy: 0.7303 - val_loss: 2.1117\nEpoch 79/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 3.0801e-06 - val_accuracy: 0.7303 - val_loss: 2.0977\nEpoch 80/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 3.0214e-06 - val_accuracy: 0.7303 - val_loss: 2.1200\nEpoch 81/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 3.0466e-06 - val_accuracy: 0.7303 - val_loss: 2.1217\nEpoch 82/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.0766e-06 - val_accuracy: 0.7321 - val_loss: 2.1243\nEpoch 83/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 2.5385e-06 - val_accuracy: 0.7303 - val_loss: 2.1312\nEpoch 84/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 2.6583e-06 - val_accuracy: 0.7303 - val_loss: 2.1393\nEpoch 85/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 2.6612e-06 - val_accuracy: 0.7321 - val_loss: 2.1506\nEpoch 86/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.3999e-06 - val_accuracy: 0.7339 - val_loss: 2.1533\nEpoch 87/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 2.4355e-06 - val_accuracy: 0.7303 - val_loss: 2.1606\nEpoch 88/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 2.1463e-06 - val_accuracy: 0.7284 - val_loss: 2.1627\nEpoch 89/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.0187e-06 - val_accuracy: 0.7321 - val_loss: 2.1750\nEpoch 90/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.9657e-06 - val_accuracy: 0.7303 - val_loss: 2.1777\nEpoch 91/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.2200e-06 - val_accuracy: 0.7303 - val_loss: 2.1770\nEpoch 92/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 2.0811e-06 - val_accuracy: 0.7321 - val_loss: 2.1838\nEpoch 93/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.7647e-06 - val_accuracy: 0.7321 - val_loss: 2.1913\nEpoch 94/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.9010e-06 - val_accuracy: 0.7358 - val_loss: 2.1885\nEpoch 95/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.6172e-06 - val_accuracy: 0.7339 - val_loss: 2.2081\nEpoch 96/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 1.6856e-06 - val_accuracy: 0.7321 - val_loss: 2.2073\nEpoch 97/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.9318e-06 - val_accuracy: 0.7321 - val_loss: 2.2172\nEpoch 98/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.4691e-06 - val_accuracy: 0.7321 - val_loss: 2.2152\nEpoch 99/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.5725e-06 - val_accuracy: 0.7321 - val_loss: 2.2186\nEpoch 100/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.5921e-06 - val_accuracy: 0.7321 - val_loss: 2.2259\nFound 1820 images belonging to 2 classes.\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8009 - loss: 1.5852\nLoss: 0.6665351390838623\nTest Accuracy: 91.98%\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394746.858064     177 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Block 3","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breakhis-400x/Breakhis-400x'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 2\nepochs = 100\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator_balanced, epochs=epochs, validation_data=validation_generator_balanced, class_weight=class_weights_balanced)\n\n# Evaluate the model on the test set\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\nloss, accuracy = model.evaluate(test_generator)\nprint('Loss:',loss)\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-11-12T06:59:06.887202Z","iopub.execute_input":"2024-11-12T06:59:06.887776Z","iopub.status.idle":"2024-11-12T07:09:59.451085Z","shell.execute_reply.started":"2024-11-12T06:59:06.887739Z","shell.execute_reply":"2024-11-12T07:09:59.450068Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 1275 images belonging to 2 classes.\nFound 545 images belonging to 2 classes.\nEpoch 1/100\n\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:41\u001b[0m 9s/step - accuracy: 0.7037 - loss: 0.6720","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394755.996255     175 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 503ms/step - accuracy: 0.5706 - loss: 2.9028","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394756.929917     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6060 - loss: 1.5414","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731394761.320880     177 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 180ms/step - accuracy: 0.6078 - loss: 1.5261 - val_accuracy: 0.8642 - val_loss: 0.3528\nEpoch 2/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.8035 - loss: 0.4925 - val_accuracy: 0.9138 - val_loss: 0.4995\nEpoch 3/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.7115 - loss: 0.5554 - val_accuracy: 0.8239 - val_loss: 0.4355\nEpoch 4/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8330 - loss: 0.4563 - val_accuracy: 0.8661 - val_loss: 0.3697\nEpoch 5/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8112 - loss: 0.4407 - val_accuracy: 0.6936 - val_loss: 0.7083\nEpoch 6/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.7850 - loss: 0.4431 - val_accuracy: 0.8404 - val_loss: 0.3741\nEpoch 7/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8489 - loss: 0.4042 - val_accuracy: 0.7835 - val_loss: 0.4745\nEpoch 8/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8696 - loss: 0.3824 - val_accuracy: 0.8257 - val_loss: 0.4224\nEpoch 9/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.8591 - loss: 0.3554 - val_accuracy: 0.7064 - val_loss: 0.7274\nEpoch 10/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8576 - loss: 0.3463 - val_accuracy: 0.8165 - val_loss: 0.4827\nEpoch 11/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8747 - loss: 0.3452 - val_accuracy: 0.7248 - val_loss: 1.2563\nEpoch 12/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.9001 - loss: 0.2732 - val_accuracy: 0.7578 - val_loss: 0.9601\nEpoch 13/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9318 - loss: 0.1987 - val_accuracy: 0.7119 - val_loss: 1.0870\nEpoch 14/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 0.9334 - loss: 0.1980 - val_accuracy: 0.7817 - val_loss: 0.9133\nEpoch 15/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9591 - loss: 0.1305 - val_accuracy: 0.7560 - val_loss: 0.9813\nEpoch 16/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9533 - loss: 0.1351 - val_accuracy: 0.7945 - val_loss: 0.6370\nEpoch 17/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9711 - loss: 0.0973 - val_accuracy: 0.7303 - val_loss: 1.8525\nEpoch 18/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9824 - loss: 0.0600 - val_accuracy: 0.7431 - val_loss: 1.1248\nEpoch 19/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.9936 - loss: 0.0301 - val_accuracy: 0.8385 - val_loss: 0.6269\nEpoch 20/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9242 - loss: 0.2369 - val_accuracy: 0.7229 - val_loss: 1.2938\nEpoch 21/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9901 - loss: 0.0440 - val_accuracy: 0.7798 - val_loss: 1.2459\nEpoch 22/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9992 - loss: 0.0101 - val_accuracy: 0.7743 - val_loss: 1.3106\nEpoch 23/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9989 - loss: 0.0114 - val_accuracy: 0.7945 - val_loss: 1.5023\nEpoch 24/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7853 - val_loss: 1.6523\nEpoch 25/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7835 - val_loss: 1.6463\nEpoch 26/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 7.8375e-04 - val_accuracy: 0.7908 - val_loss: 1.6804\nEpoch 27/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 6.1209e-04 - val_accuracy: 0.7927 - val_loss: 1.7222\nEpoch 28/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 4.7622e-04 - val_accuracy: 0.7908 - val_loss: 1.7556\nEpoch 29/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 3.7676e-04 - val_accuracy: 0.7927 - val_loss: 1.7674\nEpoch 30/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.3049e-04 - val_accuracy: 0.7890 - val_loss: 1.7835\nEpoch 31/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 2.5601e-04 - val_accuracy: 0.7835 - val_loss: 1.8033\nEpoch 32/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 2.2403e-04 - val_accuracy: 0.7817 - val_loss: 1.8258\nEpoch 33/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 2.1593e-04 - val_accuracy: 0.7927 - val_loss: 1.8450\nEpoch 34/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 1.6916e-04 - val_accuracy: 0.7927 - val_loss: 1.8509\nEpoch 35/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 1.4549e-04 - val_accuracy: 0.7817 - val_loss: 1.8668\nEpoch 36/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 1.3186e-04 - val_accuracy: 0.7835 - val_loss: 1.8782\nEpoch 37/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 1.3216e-04 - val_accuracy: 0.7835 - val_loss: 1.8906\nEpoch 38/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 1.1352e-04 - val_accuracy: 0.7872 - val_loss: 1.9030\nEpoch 39/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 9.3575e-05 - val_accuracy: 0.7872 - val_loss: 1.9109\nEpoch 40/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 8.2275e-05 - val_accuracy: 0.7908 - val_loss: 1.9360\nEpoch 41/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 8.0916e-05 - val_accuracy: 0.7890 - val_loss: 1.9426\nEpoch 42/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 7.6312e-05 - val_accuracy: 0.7908 - val_loss: 1.9575\nEpoch 43/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 6.3927e-05 - val_accuracy: 0.7908 - val_loss: 1.9701\nEpoch 44/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 5.8235e-05 - val_accuracy: 0.7853 - val_loss: 1.9630\nEpoch 45/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 5.1160e-05 - val_accuracy: 0.7872 - val_loss: 1.9811\nEpoch 46/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 5.7143e-05 - val_accuracy: 0.7890 - val_loss: 2.0032\nEpoch 47/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 5.2400e-05 - val_accuracy: 0.7853 - val_loss: 2.0084\nEpoch 48/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.9995e-05 - val_accuracy: 0.7890 - val_loss: 2.0259\nEpoch 49/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 3.9060e-05 - val_accuracy: 0.7835 - val_loss: 2.0121\nEpoch 50/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 3.9227e-05 - val_accuracy: 0.7890 - val_loss: 2.0496\nEpoch 51/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 3.4807e-05 - val_accuracy: 0.7853 - val_loss: 2.0513\nEpoch 52/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 3.2491e-05 - val_accuracy: 0.7798 - val_loss: 2.0518\nEpoch 53/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 2.8572e-05 - val_accuracy: 0.7817 - val_loss: 2.0645\nEpoch 54/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 2.7300e-05 - val_accuracy: 0.7798 - val_loss: 2.0732\nEpoch 55/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 2.8913e-05 - val_accuracy: 0.7817 - val_loss: 2.0901\nEpoch 56/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 2.7335e-05 - val_accuracy: 0.7835 - val_loss: 2.1178\nEpoch 57/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 2.6753e-05 - val_accuracy: 0.7817 - val_loss: 2.1180\nEpoch 58/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 2.4451e-05 - val_accuracy: 0.7780 - val_loss: 2.1072\nEpoch 59/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.4185e-05 - val_accuracy: 0.7817 - val_loss: 2.1267\nEpoch 60/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.0099e-05 - val_accuracy: 0.7817 - val_loss: 2.1286\nEpoch 61/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.2676e-05 - val_accuracy: 0.7817 - val_loss: 2.1334\nEpoch 62/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.0611e-05 - val_accuracy: 0.7817 - val_loss: 2.1516\nEpoch 63/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.5089e-05 - val_accuracy: 0.7817 - val_loss: 2.1849\nEpoch 64/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.6038e-05 - val_accuracy: 0.7817 - val_loss: 2.1868\nEpoch 65/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 1.6259e-05 - val_accuracy: 0.7835 - val_loss: 2.1910\nEpoch 66/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 1.6389e-05 - val_accuracy: 0.7853 - val_loss: 2.1983\nEpoch 67/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.3675e-05 - val_accuracy: 0.7817 - val_loss: 2.2034\nEpoch 68/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 1.5477e-05 - val_accuracy: 0.7817 - val_loss: 2.2075\nEpoch 69/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.3870e-05 - val_accuracy: 0.7817 - val_loss: 2.2143\nEpoch 70/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.2101e-05 - val_accuracy: 0.7817 - val_loss: 2.2192\nEpoch 71/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.4348e-05 - val_accuracy: 0.7817 - val_loss: 2.2208\nEpoch 72/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.1725e-05 - val_accuracy: 0.7817 - val_loss: 2.2493\nEpoch 73/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 1.1479e-05 - val_accuracy: 0.7798 - val_loss: 2.2542\nEpoch 74/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 1.0159e-05 - val_accuracy: 0.7835 - val_loss: 2.2575\nEpoch 75/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.1081e-05 - val_accuracy: 0.7798 - val_loss: 2.2790\nEpoch 76/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.0690e-05 - val_accuracy: 0.7817 - val_loss: 2.2716\nEpoch 77/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 1.0201e-05 - val_accuracy: 0.7780 - val_loss: 2.2907\nEpoch 78/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 9.2519e-06 - val_accuracy: 0.7798 - val_loss: 2.2931\nEpoch 79/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 8.5342e-06 - val_accuracy: 0.7780 - val_loss: 2.3145\nEpoch 80/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 9.2038e-06 - val_accuracy: 0.7780 - val_loss: 2.3094\nEpoch 81/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 7.9614e-06 - val_accuracy: 0.7761 - val_loss: 2.3300\nEpoch 82/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 8.6965e-06 - val_accuracy: 0.7761 - val_loss: 2.3199\nEpoch 83/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 7.5352e-06 - val_accuracy: 0.7780 - val_loss: 2.3385\nEpoch 84/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 7.7151e-06 - val_accuracy: 0.7761 - val_loss: 2.3531\nEpoch 85/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 7.6375e-06 - val_accuracy: 0.7743 - val_loss: 2.3409\nEpoch 86/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 7.7512e-06 - val_accuracy: 0.7817 - val_loss: 2.3616\nEpoch 87/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 6.7353e-06 - val_accuracy: 0.7761 - val_loss: 2.3642\nEpoch 88/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 6.0804e-06 - val_accuracy: 0.7780 - val_loss: 2.3772\nEpoch 89/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 6.4138e-06 - val_accuracy: 0.7780 - val_loss: 2.3833\nEpoch 90/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 6.5919e-06 - val_accuracy: 0.7743 - val_loss: 2.3769\nEpoch 91/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 5.2105e-06 - val_accuracy: 0.7780 - val_loss: 2.4113\nEpoch 92/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 6.4783e-06 - val_accuracy: 0.7743 - val_loss: 2.3952\nEpoch 93/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 4.9288e-06 - val_accuracy: 0.7743 - val_loss: 2.4061\nEpoch 94/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 5.2615e-06 - val_accuracy: 0.7743 - val_loss: 2.4139\nEpoch 95/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 4.8089e-06 - val_accuracy: 0.7743 - val_loss: 2.4030\nEpoch 96/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 5.2859e-06 - val_accuracy: 0.7743 - val_loss: 2.4193\nEpoch 97/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 4.6614e-06 - val_accuracy: 0.7761 - val_loss: 2.4463\nEpoch 98/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 4.7184e-06 - val_accuracy: 0.7743 - val_loss: 2.4342\nEpoch 99/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 4.0177e-06 - val_accuracy: 0.7725 - val_loss: 2.4525\nEpoch 100/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 3.9410e-06 - val_accuracy: 0.7761 - val_loss: 2.4595\nFound 1820 images belonging to 2 classes.\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.8431 - loss: 1.6844\nLoss: 0.736501157283783\nTest Accuracy: 93.30%\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731395399.422451     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# Block 5","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breakhis-400x/Breakhis-400x'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 2\nepochs = 100\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator_balanced, epochs=epochs, validation_data=validation_generator_balanced, class_weight=class_weights_balanced)\n\n# Evaluate the model on the test set\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\nloss, accuracy = model.evaluate(test_generator)\nprint('Loss:',loss)\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')or_balanced, epochs=epochs, validation_data=validation_generator_balanced, class_weight=class_weights_balanced)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-12T07:20:44.790476Z","iopub.execute_input":"2024-11-12T07:20:44.790786Z","iopub.status.idle":"2024-11-12T07:31:20.558527Z","shell.execute_reply.started":"2024-11-12T07:20:44.790759Z","shell.execute_reply":"2024-11-12T07:31:20.557548Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 1275 images belonging to 2 classes.\nFound 545 images belonging to 2 classes.\nEpoch 1/100\n\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.4375 - loss: 0.6985","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731396048.982961     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 952ms/step - accuracy: 0.4557 - loss: 0.7272","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731396052.677716     175 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.5140 - loss: 0.7052","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731396056.831696     178 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 245ms/step - accuracy: 0.5161 - loss: 0.7038 - val_accuracy: 0.8495 - val_loss: 0.4193\nEpoch 2/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.7697 - loss: 0.5583 - val_accuracy: 0.8550 - val_loss: 0.5225\nEpoch 3/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8095 - loss: 0.5366 - val_accuracy: 0.8917 - val_loss: 0.4706\nEpoch 4/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.7680 - loss: 0.5358 - val_accuracy: 0.8569 - val_loss: 0.4458\nEpoch 5/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8330 - loss: 0.5059 - val_accuracy: 0.8954 - val_loss: 0.4037\nEpoch 6/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.8107 - loss: 0.5007 - val_accuracy: 0.9009 - val_loss: 0.3440\nEpoch 7/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8169 - loss: 0.4978 - val_accuracy: 0.9174 - val_loss: 0.3714\nEpoch 8/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8256 - loss: 0.4928 - val_accuracy: 0.8881 - val_loss: 0.4797\nEpoch 9/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.8089 - loss: 0.5411 - val_accuracy: 0.8954 - val_loss: 0.3172\nEpoch 10/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8227 - loss: 0.4873 - val_accuracy: 0.8899 - val_loss: 0.3910\nEpoch 11/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.8160 - loss: 0.4853 - val_accuracy: 0.7284 - val_loss: 0.5844\nEpoch 12/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.7712 - loss: 0.5942 - val_accuracy: 0.8569 - val_loss: 0.4106\nEpoch 13/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.8313 - loss: 0.4795 - val_accuracy: 0.8587 - val_loss: 0.4938\nEpoch 14/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.8088 - loss: 0.5073 - val_accuracy: 0.8844 - val_loss: 0.3565\nEpoch 15/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.8426 - loss: 0.4532 - val_accuracy: 0.8826 - val_loss: 0.4516\nEpoch 16/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.8601 - loss: 0.4367 - val_accuracy: 0.8936 - val_loss: 0.4025\nEpoch 17/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8068 - loss: 0.5025 - val_accuracy: 0.8862 - val_loss: 0.4058\nEpoch 18/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.8428 - loss: 0.4748 - val_accuracy: 0.8734 - val_loss: 0.4008\nEpoch 19/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8554 - loss: 0.4171 - val_accuracy: 0.8972 - val_loss: 0.4002\nEpoch 20/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8514 - loss: 0.4363 - val_accuracy: 0.7248 - val_loss: 0.6240\nEpoch 21/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7753 - loss: 0.5259 - val_accuracy: 0.8679 - val_loss: 0.5090\nEpoch 22/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8471 - loss: 0.4308 - val_accuracy: 0.8459 - val_loss: 0.4592\nEpoch 23/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.8179 - loss: 0.4711 - val_accuracy: 0.8661 - val_loss: 0.4643\nEpoch 24/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8585 - loss: 0.4242 - val_accuracy: 0.8404 - val_loss: 0.5499\nEpoch 25/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8501 - loss: 0.4104 - val_accuracy: 0.8624 - val_loss: 0.4711\nEpoch 26/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.8593 - loss: 0.4101 - val_accuracy: 0.8275 - val_loss: 0.6144\nEpoch 27/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.8585 - loss: 0.3949 - val_accuracy: 0.8239 - val_loss: 0.6287\nEpoch 28/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8698 - loss: 0.3575 - val_accuracy: 0.8807 - val_loss: 0.5039\nEpoch 29/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8839 - loss: 0.3231 - val_accuracy: 0.8330 - val_loss: 0.8652\nEpoch 30/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.8801 - loss: 0.3392 - val_accuracy: 0.8679 - val_loss: 0.6558\nEpoch 31/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8913 - loss: 0.2658 - val_accuracy: 0.8202 - val_loss: 0.6767\nEpoch 32/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 0.8959 - loss: 0.2837 - val_accuracy: 0.8239 - val_loss: 0.6426\nEpoch 33/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9217 - loss: 0.1977 - val_accuracy: 0.7945 - val_loss: 1.0836\nEpoch 34/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8992 - loss: 0.2908 - val_accuracy: 0.8330 - val_loss: 0.7583\nEpoch 35/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9290 - loss: 0.1868 - val_accuracy: 0.8550 - val_loss: 0.7883\nEpoch 36/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.9292 - loss: 0.1845 - val_accuracy: 0.8257 - val_loss: 0.9146\nEpoch 37/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8953 - loss: 0.2850 - val_accuracy: 0.6807 - val_loss: 0.6480\nEpoch 38/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.5769 - loss: 0.6983 - val_accuracy: 0.6771 - val_loss: 0.6762\nEpoch 39/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - accuracy: 0.6715 - loss: 0.6878 - val_accuracy: 0.7633 - val_loss: 0.5954\nEpoch 40/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.6890 - loss: 0.6239 - val_accuracy: 0.7908 - val_loss: 0.5078\nEpoch 41/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.7178 - loss: 0.5855 - val_accuracy: 0.7853 - val_loss: 0.5580\nEpoch 42/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.7632 - loss: 0.5813 - val_accuracy: 0.8771 - val_loss: 0.3898\nEpoch 43/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7924 - loss: 0.5397 - val_accuracy: 0.8734 - val_loss: 0.4291\nEpoch 44/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8211 - loss: 0.4726 - val_accuracy: 0.6477 - val_loss: 0.6583\nEpoch 45/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.7834 - loss: 0.5046 - val_accuracy: 0.7706 - val_loss: 0.5059\nEpoch 46/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8388 - loss: 0.4034 - val_accuracy: 0.7560 - val_loss: 0.5268\nEpoch 47/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8527 - loss: 0.3631 - val_accuracy: 0.7596 - val_loss: 0.4930\nEpoch 48/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8539 - loss: 0.3557 - val_accuracy: 0.8110 - val_loss: 0.4861\nEpoch 49/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.8688 - loss: 0.3300 - val_accuracy: 0.7064 - val_loss: 0.6810\nEpoch 50/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8682 - loss: 0.3287 - val_accuracy: 0.7706 - val_loss: 0.6757\nEpoch 51/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9001 - loss: 0.2707 - val_accuracy: 0.7009 - val_loss: 0.7945\nEpoch 52/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8247 - loss: 0.3967 - val_accuracy: 0.7835 - val_loss: 0.5588\nEpoch 53/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9254 - loss: 0.2125 - val_accuracy: 0.6881 - val_loss: 1.2282\nEpoch 54/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9097 - loss: 0.2392 - val_accuracy: 0.7376 - val_loss: 0.8397\nEpoch 55/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.9436 - loss: 0.1467 - val_accuracy: 0.7688 - val_loss: 1.0573\nEpoch 56/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.9608 - loss: 0.1085 - val_accuracy: 0.7835 - val_loss: 1.0408\nEpoch 57/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.9260 - loss: 0.1764 - val_accuracy: 0.6807 - val_loss: 1.1240\nEpoch 58/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9342 - loss: 0.1718 - val_accuracy: 0.7028 - val_loss: 1.4054\nEpoch 59/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9420 - loss: 0.1301 - val_accuracy: 0.7560 - val_loss: 1.4986\nEpoch 60/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.9358 - loss: 0.1309 - val_accuracy: 0.7450 - val_loss: 1.5325\nEpoch 61/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9805 - loss: 0.0590 - val_accuracy: 0.7578 - val_loss: 1.5515\nEpoch 62/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9837 - loss: 0.0400 - val_accuracy: 0.7633 - val_loss: 1.6922\nEpoch 63/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9930 - loss: 0.0279 - val_accuracy: 0.7615 - val_loss: 1.8964\nEpoch 64/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.9878 - loss: 0.0335 - val_accuracy: 0.7413 - val_loss: 2.2651\nEpoch 65/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9876 - loss: 0.0327 - val_accuracy: 0.7523 - val_loss: 1.8256\nEpoch 66/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9802 - loss: 0.0521 - val_accuracy: 0.7028 - val_loss: 1.4383\nEpoch 67/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.9387 - loss: 0.1788 - val_accuracy: 0.7376 - val_loss: 1.1403\nEpoch 68/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9769 - loss: 0.0513 - val_accuracy: 0.7872 - val_loss: 1.2019\nEpoch 69/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9882 - loss: 0.0268 - val_accuracy: 0.7688 - val_loss: 1.4857\nEpoch 70/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.7725 - val_loss: 1.7219\nEpoch 71/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.7670 - val_loss: 1.8336\nEpoch 72/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7725 - val_loss: 1.9433\nEpoch 73/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7853 - val_loss: 1.9588\nEpoch 74/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 8.7830e-04 - val_accuracy: 0.7780 - val_loss: 1.9505\nEpoch 75/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 5.4511e-04 - val_accuracy: 0.7798 - val_loss: 2.0512\nEpoch 76/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 6.8674e-04 - val_accuracy: 0.7817 - val_loss: 2.0079\nEpoch 77/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 4.8244e-04 - val_accuracy: 0.7835 - val_loss: 2.0898\nEpoch 78/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 3.5884e-04 - val_accuracy: 0.7835 - val_loss: 2.0920\nEpoch 79/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 3.0472e-04 - val_accuracy: 0.7817 - val_loss: 2.1412\nEpoch 80/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 2.5285e-04 - val_accuracy: 0.7872 - val_loss: 2.1092\nEpoch 81/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 2.3278e-04 - val_accuracy: 0.7890 - val_loss: 2.1191\nEpoch 82/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.0894e-04 - val_accuracy: 0.7853 - val_loss: 2.1407\nEpoch 83/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.7669e-04 - val_accuracy: 0.7890 - val_loss: 2.1793\nEpoch 84/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.4427e-04 - val_accuracy: 0.7872 - val_loss: 2.1988\nEpoch 85/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 1.3244e-04 - val_accuracy: 0.7872 - val_loss: 2.2130\nEpoch 86/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.2185e-04 - val_accuracy: 0.7872 - val_loss: 2.2170\nEpoch 87/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.2526e-04 - val_accuracy: 0.7872 - val_loss: 2.2184\nEpoch 88/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.1247e-04 - val_accuracy: 0.7890 - val_loss: 2.2495\nEpoch 89/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 9.6565e-05 - val_accuracy: 0.7908 - val_loss: 2.2309\nEpoch 90/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 8.2444e-05 - val_accuracy: 0.7890 - val_loss: 2.2896\nEpoch 91/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 7.1787e-05 - val_accuracy: 0.7853 - val_loss: 2.2545\nEpoch 92/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 7.6550e-05 - val_accuracy: 0.7890 - val_loss: 2.2665\nEpoch 93/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 6.4237e-05 - val_accuracy: 0.7872 - val_loss: 2.2825\nEpoch 94/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 6.2571e-05 - val_accuracy: 0.7872 - val_loss: 2.2944\nEpoch 95/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 6.0545e-05 - val_accuracy: 0.7872 - val_loss: 2.2872\nEpoch 96/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 5.8317e-05 - val_accuracy: 0.7872 - val_loss: 2.3348\nEpoch 97/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 4.6576e-05 - val_accuracy: 0.7872 - val_loss: 2.3410\nEpoch 98/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 4.7931e-05 - val_accuracy: 0.7872 - val_loss: 2.3308\nEpoch 99/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 5.2105e-05 - val_accuracy: 0.7872 - val_loss: 2.3415\nEpoch 100/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 4.7130e-05 - val_accuracy: 0.7890 - val_loss: 2.3449\nFound 1820 images belonging to 2 classes.\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.8455 - loss: 1.9696\nLoss: 0.7022069096565247\nTest Accuracy: 93.68%\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731396680.536972     176 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# Block 6","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Set the path to your balanced dataset\nbalanced_dataset_path = '/kaggle/input/breakhis-400x/Breakhis-400x'\n\n# Set the image dimensions and other parameters\ninput_shape = (224, 224, 3)\nbatch_size = 32\nnum_classes = 2\nepochs = 100\n\n# Create the data generator for training and validation without data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\nvalidation_generator_balanced = train_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Calculate the class weights to handle data imbalance\nclass_weights_balanced = dict(zip(range(num_classes), ((len(train_generator_balanced.classes) / (num_classes * np.bincount(train_generator_balanced.classes))).tolist())))\n\n# Build the CNN model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator_balanced, epochs=epochs, validation_data=validation_generator_balanced, class_weight=class_weights_balanced)\n\n# Evaluate the model on the test set\ntest_generator = test_datagen.flow_from_directory(\n    balanced_dataset_path,\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\nloss, accuracy = model.evaluate(test_generator)\nprint('Loss:',loss)\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-11-12T07:31:20.560216Z","iopub.execute_input":"2024-11-12T07:31:20.560773Z","iopub.status.idle":"2024-11-12T07:41:56.448385Z","shell.execute_reply.started":"2024-11-12T07:31:20.560738Z","shell.execute_reply":"2024-11-12T07:41:56.447444Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Found 1275 images belonging to 2 classes.\nFound 545 images belonging to 2 classes.\nEpoch 1/100\n\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.6875 - loss: 0.7200","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1731396685.096708     178 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 241ms/step - accuracy: 0.5201 - loss: 0.7117 - val_accuracy: 0.6771 - val_loss: 0.6736\nEpoch 2/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.6958 - loss: 0.6647 - val_accuracy: 0.8257 - val_loss: 0.4484\nEpoch 3/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.7847 - loss: 0.5538 - val_accuracy: 0.8385 - val_loss: 0.5307\nEpoch 4/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.7724 - loss: 0.5821 - val_accuracy: 0.7872 - val_loss: 0.6103\nEpoch 5/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.8197 - loss: 0.5585 - val_accuracy: 0.7193 - val_loss: 0.6124\nEpoch 6/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.7488 - loss: 0.5611 - val_accuracy: 0.7284 - val_loss: 0.5184\nEpoch 7/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7788 - loss: 0.5410 - val_accuracy: 0.8697 - val_loss: 0.4091\nEpoch 8/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.8376 - loss: 0.4668 - val_accuracy: 0.8440 - val_loss: 0.4536\nEpoch 9/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8326 - loss: 0.4727 - val_accuracy: 0.8018 - val_loss: 0.5632\nEpoch 10/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.7754 - loss: 0.5744 - val_accuracy: 0.8312 - val_loss: 0.3989\nEpoch 11/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.8414 - loss: 0.4665 - val_accuracy: 0.8092 - val_loss: 0.4902\nEpoch 12/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8389 - loss: 0.4273 - val_accuracy: 0.8954 - val_loss: 0.4581\nEpoch 13/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7860 - loss: 0.5129 - val_accuracy: 0.8972 - val_loss: 0.4287\nEpoch 14/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.8333 - loss: 0.4851 - val_accuracy: 0.7817 - val_loss: 0.5467\nEpoch 15/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.7903 - loss: 0.5189 - val_accuracy: 0.8477 - val_loss: 0.3742\nEpoch 16/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8208 - loss: 0.4808 - val_accuracy: 0.8385 - val_loss: 0.4675\nEpoch 17/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8531 - loss: 0.4157 - val_accuracy: 0.7706 - val_loss: 0.7637\nEpoch 18/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.8318 - loss: 0.4363 - val_accuracy: 0.7358 - val_loss: 0.5126\nEpoch 19/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8117 - loss: 0.4580 - val_accuracy: 0.8514 - val_loss: 0.4045\nEpoch 20/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.8502 - loss: 0.4127 - val_accuracy: 0.8514 - val_loss: 0.4108\nEpoch 21/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8402 - loss: 0.4264 - val_accuracy: 0.9028 - val_loss: 0.2703\nEpoch 22/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8273 - loss: 0.4752 - val_accuracy: 0.7541 - val_loss: 0.6811\nEpoch 23/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 140ms/step - accuracy: 0.8460 - loss: 0.3906 - val_accuracy: 0.7835 - val_loss: 0.6281\nEpoch 24/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.8410 - loss: 0.4184 - val_accuracy: 0.8899 - val_loss: 0.2992\nEpoch 25/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8593 - loss: 0.3945 - val_accuracy: 0.8459 - val_loss: 0.4935\nEpoch 26/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.8609 - loss: 0.4411 - val_accuracy: 0.8092 - val_loss: 0.5064\nEpoch 27/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.8254 - loss: 0.4849 - val_accuracy: 0.8330 - val_loss: 0.4394\nEpoch 28/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8410 - loss: 0.4278 - val_accuracy: 0.8165 - val_loss: 0.5181\nEpoch 29/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - accuracy: 0.8411 - loss: 0.4283 - val_accuracy: 0.8661 - val_loss: 0.4015\nEpoch 30/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8572 - loss: 0.3904 - val_accuracy: 0.8294 - val_loss: 0.6523\nEpoch 31/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.8484 - loss: 0.3834 - val_accuracy: 0.7431 - val_loss: 1.1517\nEpoch 32/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8833 - loss: 0.3011 - val_accuracy: 0.8606 - val_loss: 0.4461\nEpoch 33/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.8290 - loss: 0.4316 - val_accuracy: 0.8330 - val_loss: 0.5226\nEpoch 34/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.8667 - loss: 0.3644 - val_accuracy: 0.7578 - val_loss: 0.8424\nEpoch 35/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.8521 - loss: 0.3807 - val_accuracy: 0.8055 - val_loss: 0.9404\nEpoch 36/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8957 - loss: 0.3066 - val_accuracy: 0.8385 - val_loss: 0.6602\nEpoch 37/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8770 - loss: 0.3325 - val_accuracy: 0.7835 - val_loss: 0.7325\nEpoch 38/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.8738 - loss: 0.3093 - val_accuracy: 0.9339 - val_loss: 0.3364\nEpoch 39/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8664 - loss: 0.4199 - val_accuracy: 0.9193 - val_loss: 0.3356\nEpoch 40/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8559 - loss: 0.3951 - val_accuracy: 0.9193 - val_loss: 0.3430\nEpoch 41/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.8653 - loss: 0.3642 - val_accuracy: 0.8972 - val_loss: 0.3769\nEpoch 42/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8859 - loss: 0.3302 - val_accuracy: 0.8220 - val_loss: 0.5368\nEpoch 43/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8181 - loss: 0.4840 - val_accuracy: 0.8752 - val_loss: 0.4066\nEpoch 44/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.8597 - loss: 0.3993 - val_accuracy: 0.8954 - val_loss: 0.4081\nEpoch 45/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.8726 - loss: 0.3913 - val_accuracy: 0.9009 - val_loss: 0.4069\nEpoch 46/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8795 - loss: 0.3627 - val_accuracy: 0.8404 - val_loss: 0.5471\nEpoch 47/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8712 - loss: 0.3720 - val_accuracy: 0.8367 - val_loss: 0.6034\nEpoch 48/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.8534 - loss: 0.4030 - val_accuracy: 0.9229 - val_loss: 0.3405\nEpoch 49/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.8711 - loss: 0.3546 - val_accuracy: 0.8606 - val_loss: 0.4774\nEpoch 50/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.8318 - loss: 0.3936 - val_accuracy: 0.7743 - val_loss: 0.8571\nEpoch 51/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.8850 - loss: 0.2858 - val_accuracy: 0.7743 - val_loss: 0.8736\nEpoch 52/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 0.9182 - loss: 0.1900 - val_accuracy: 0.8147 - val_loss: 0.9233\nEpoch 53/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9321 - loss: 0.1795 - val_accuracy: 0.7706 - val_loss: 1.2538\nEpoch 54/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9267 - loss: 0.1850 - val_accuracy: 0.8752 - val_loss: 0.4835\nEpoch 55/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.9565 - loss: 0.1394 - val_accuracy: 0.8477 - val_loss: 0.8130\nEpoch 56/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9577 - loss: 0.1368 - val_accuracy: 0.8239 - val_loss: 1.1072\nEpoch 57/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9524 - loss: 0.1189 - val_accuracy: 0.7908 - val_loss: 1.1252\nEpoch 58/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.9125 - loss: 0.2392 - val_accuracy: 0.6917 - val_loss: 1.7474\nEpoch 59/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.9456 - loss: 0.1296 - val_accuracy: 0.7560 - val_loss: 1.1740\nEpoch 60/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.9384 - loss: 0.1408 - val_accuracy: 0.7321 - val_loss: 1.5308\nEpoch 61/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9136 - loss: 0.2473 - val_accuracy: 0.8073 - val_loss: 0.6972\nEpoch 62/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9307 - loss: 0.2112 - val_accuracy: 0.7596 - val_loss: 1.4231\nEpoch 63/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9657 - loss: 0.1009 - val_accuracy: 0.7394 - val_loss: 1.6214\nEpoch 64/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.9744 - loss: 0.0792 - val_accuracy: 0.8404 - val_loss: 0.9734\nEpoch 65/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.9867 - loss: 0.0689 - val_accuracy: 0.8165 - val_loss: 1.3579\nEpoch 66/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9785 - loss: 0.0560 - val_accuracy: 0.8367 - val_loss: 1.5495\nEpoch 67/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9864 - loss: 0.0548 - val_accuracy: 0.8147 - val_loss: 1.7968\nEpoch 68/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.9230 - loss: 0.3110 - val_accuracy: 0.8624 - val_loss: 0.3797\nEpoch 69/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9192 - loss: 0.2880 - val_accuracy: 0.8183 - val_loss: 0.9336\nEpoch 70/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9689 - loss: 0.1152 - val_accuracy: 0.7817 - val_loss: 1.4839\nEpoch 71/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.9475 - loss: 0.1656 - val_accuracy: 0.8294 - val_loss: 0.8414\nEpoch 72/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9541 - loss: 0.1272 - val_accuracy: 0.8000 - val_loss: 1.5314\nEpoch 73/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9825 - loss: 0.0718 - val_accuracy: 0.7963 - val_loss: 1.4578\nEpoch 74/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.9932 - loss: 0.0317 - val_accuracy: 0.7963 - val_loss: 1.8774\nEpoch 75/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9901 - loss: 0.0360 - val_accuracy: 0.7468 - val_loss: 2.3242\nEpoch 76/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - accuracy: 0.9767 - loss: 0.0600 - val_accuracy: 0.7835 - val_loss: 1.5895\nEpoch 77/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.9865 - loss: 0.0382 - val_accuracy: 0.6624 - val_loss: 3.5164\nEpoch 78/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.9907 - loss: 0.0448 - val_accuracy: 0.7468 - val_loss: 2.6165\nEpoch 79/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.9999 - loss: 0.0054 - val_accuracy: 0.7266 - val_loss: 3.1841\nEpoch 80/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.9954 - loss: 0.0136 - val_accuracy: 0.7706 - val_loss: 2.6225\nEpoch 81/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.9897 - loss: 0.0348 - val_accuracy: 0.7982 - val_loss: 2.1551\nEpoch 82/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9936 - loss: 0.0429 - val_accuracy: 0.7523 - val_loss: 2.5601\nEpoch 83/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.9999 - loss: 0.0086 - val_accuracy: 0.7651 - val_loss: 2.8004\nEpoch 84/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7651 - val_loss: 2.8993\nEpoch 85/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 6.6846e-04 - val_accuracy: 0.7853 - val_loss: 2.9612\nEpoch 86/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 5.9402e-04 - val_accuracy: 0.7853 - val_loss: 3.0101\nEpoch 87/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 4.1789e-04 - val_accuracy: 0.7817 - val_loss: 3.0710\nEpoch 88/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 3.0340e-04 - val_accuracy: 0.7817 - val_loss: 3.1358\nEpoch 89/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 3.1503e-04 - val_accuracy: 0.7817 - val_loss: 3.1818\nEpoch 90/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 2.4993e-04 - val_accuracy: 0.7798 - val_loss: 3.2157\nEpoch 91/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 2.7614e-04 - val_accuracy: 0.7798 - val_loss: 3.2614\nEpoch 92/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 2.1028e-04 - val_accuracy: 0.7817 - val_loss: 3.3007\nEpoch 93/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 1.9066e-04 - val_accuracy: 0.7817 - val_loss: 3.3365\nEpoch 94/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 1.6370e-04 - val_accuracy: 0.7835 - val_loss: 3.3808\nEpoch 95/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.6445e-04 - val_accuracy: 0.7835 - val_loss: 3.4014\nEpoch 96/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 1.7024e-04 - val_accuracy: 0.7853 - val_loss: 3.4352\nEpoch 97/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 1.5491e-04 - val_accuracy: 0.7872 - val_loss: 3.4663\nEpoch 98/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.1251e-04 - val_accuracy: 0.7872 - val_loss: 3.4933\nEpoch 99/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.0816e-04 - val_accuracy: 0.7853 - val_loss: 3.5199\nEpoch 100/100\n\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.1422e-04 - val_accuracy: 0.7908 - val_loss: 3.5542\nFound 1820 images belonging to 2 classes.\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8504 - loss: 2.4298\nLoss: 1.0643893480300903\nTest Accuracy: 93.74%\n","output_type":"stream"}],"execution_count":26}]}